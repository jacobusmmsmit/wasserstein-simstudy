cost_mat <- costMatrix(muhat, nuhat, 3)
cost_mat
cost_mat <- costMatrix(muhat, nuhat, 2)
cost_mat
type(costMatrix)
typeof(costMatrix)
typeof(mean)
typeof(as.data.frame())
typeof(as.data.frame
)
sourceCpp("costMatrix.cpp")
sourceCpp("src/costMatrix.cpp")
sourceCpp("src/costMatrix.cpp")
sourceCpp("src/costMatrix.cpp")
sourceCpp("src/costMatrix.cpp")
sourceCpp("src/costMatrix.cpp")
sourceCpp("src/costMatrix.cpp")
sourceCpp("src/costMatrix.cpp")
sourceCpp("src/costMatrix.cpp")
sourceCpp("src/costMatrix.cpp")
sourceCpp("src/costMatrix.cpp")
sourceCpp("src/costMatrix.cpp")
sourceCpp("src/costMatrix.cpp")
sourceCpp("src/costMatrix.cpp")
sourceCpp("src/costMatrix.cpp")#
cost_mat
cost_mat2 <- costmat
cost_mat2 <- cost_mat
cost_mat <- costMatrix(muhat, nuhat, 2, 2)
cost_mat2 == cost_mat
cost_mat
sourceCpp("src/costMatrix.cpp")#
cost_mat <- costMatrix(muhat, nuhat, 2, 2)
cost_mat
sourceCpp("src/costMatrix.cpp")#
cost_mat <- costMatrix(muhat, nuhat, 2, 2)
cost_mat
sourceCpp("src/costMatrix.cpp")
cost_mat <- costMatrix(muhat, nuhat, 2, 2)
cost_mat
install.packages("JuliaCall")
julia <- julia_setup()
library(JuliaCall)
julia <- julia_setup()
julia <- julia_setup()
julia <- julia_setup()
require(JuliaCall)
julia <- julia_setup()
# require(JuliaCall)
# julia <- julia_setup()
require(Rcpp)
sourceCpp("src/network_simplex_fast.cpp") # Compile and load the solver. The header files are also necessary.
sourceCpp("src/costMatrix.cpp")
# Investigate:
# Easy ("Good"): Look at variance of Wp^p (wasserstein p distance to the p) and Wp when ?? = ?? as N increases
# Loop, store distance, compute estimator of sample variance (1/n ? sum((xi - x??)^2))
# var(c(10 9 8 7 6 5 4 3 2 1))
# pattern: want plot variance against N, definintely for Wp^p goes down faster than 1/n, interesting: find out the exponent.
# it's n^-c c> 1 but how big is this and how does it depend on dimension
# How to see what size of c is:
# Imagine I know a-priori it's logvar = logc * c log(n)
# log log plot of variance against sample size then slope = c < -1
# Then take p^th root then calculate variance and then loglog plot of variance against sample size
# Pattern should be the same for whatever mertic and exponent p > 1
# Which exact metic to take and which exponent tot ake is pretty wide
# Start with euclidean norm exponent 2, then integer exponents
# Sample size up to 10,000
# Replicates: A couple
# Wasserstein takes a metric d and then (integral( d(x - y) ^p)^1/p
# d <- function(x, y, q = 2) {(sum(x - y)^q)^(1/q)} # = Lq-norm which then induces a metric but yeah
# preliminary investigation: CLT papers on Optimal transport ?? if I would like (only, otherwise do not, i repeat do not unless you would like)
# Came out february, good papers -> you must enjoy them. contains refernece to previous work which is pretty good
# https://arxiv.org/pdf/2102.06379.pdf
# require(JuliaCall)
# julia <- julia_setup()
require(Rcpp)
sourceCpp("src/network_simplex_fast.cpp") # Compile and load the solver. The header files are also necessary.
sourceCpp("src/costMatrix.cpp")
# julia_source("src/costMatrix.jl")
n <- 1000 # Sample size
d <- 10   # Dimension
# 1.) Generate samples (they don't have to be normal)
muhat <- matrix(rnorm(n * d), nrow = d) # n samples from a standard normal, stored as one sample per column
nuhat <- matrix(rnorm(n * d), nrow = d)
# 2.) Compute the cost matrix
# If x_i is the i-th sample from mu, its entries are c_{ij} = 1/n * ||x_i - y_i||_2^2.
# In general, you'll do c_{ij} = 1/n * d(x_i, y_i)^p.
cost_mat <- costMatrix(muhat, nuhat, 2, 2) # L-2 metric, wasserstein 2 norm
cm <- costMatrix(muhat, nuhat, 2, 2) # L-2 metric, wasserstein 2 norm
# cm2 <- julia_call("costMatrixjl", muhat,nuhat, 2, 2)
# remake the cost matrix
# 3.) Compute the distance from the cost matrix
w2_empirical <- sqrt(SolveAssignmentNetworkflow(cost_mat))
w2_empirical
muhat
for (i in 1:10){
print(i)
}
print(muhat[1:i, 1:i])
for (i in 1:10){
print(muhat[1:i, 1:i])
}
w2_emp <- []
w2_emp <- c()
for (i in 1:10){
mh <- muhat[1:i, 1:i]
nh <- nuhat[1:i, 1:i]
cm <- costMatrix(mh, nh, 2, 2)
w2_emp[i] <- sqrt(SolveAssignmentNetworkflow(cm))
}
muhat[1:i, 1:i]
for (i in 2:10){
mh <- muhat[1:i, 1:i]
nh <- nuhat[1:i, 1:i]
cm <- costMatrix(mh, nh, 2, 2)
w2_emp[i] <- sqrt(SolveAssignmentNetworkflow(cm))
}
w2_emp
w2_emp <- c()
for (i in 2:10){
mh <- muhat[1:i, 1:i]
nh <- nuhat[1:i, 1:i]
cm <- costMatrix(mh, nh, 2, 2)
w2_emp[i-1] <- sqrt(SolveAssignmentNetworkflow(cm))
}
w2_emp
w2_emp <- c()
for (i in 2:100){
mh <- muhat[1:i, 1:i]
nh <- nuhat[1:i, 1:i]
cm <- costMatrix(mh, nh, 2, 2)
w2_emp[i-1] <- sqrt(SolveAssignmentNetworkflow(cm))
}
muhat
size(muhat)
nrows(muhat)
dim(muhat)
w2_emp <- c()
for (i in 2:100){
mh <- muhat[10, 1:i]
nh <- nuhat[10, 1:i]
cm <- costMatrix(mh, nh, 2, 2)
w2_emp[i-1] <- sqrt(SolveAssignmentNetworkflow(cm))
}
for (i in 2:100){
mh <- muhat[10, 1:i]
nh <- nuhat[10, 1:i]
print(i)
cm <- costMatrix(mh, nh, 2, 2)
w2_emp[i-1] <- sqrt(SolveAssignmentNetworkflow(cm))
}
for (i in 2:100){
mh <- muhat[10, 1:i]
nh <- nuhat[10, 1:i]
print(mh)
cm <- costMatrix(mh, nh, 2, 2)
w2_emp[i-1] <- sqrt(SolveAssignmentNetworkflow(cm))
}
for (i in 2:100){
mh <- muhat[1:10, 1:i]
nh <- nuhat[1:10, 1:i]
print(mh)
cm <- costMatrix(mh, nh, 2, 2)
w2_emp[i-1] <- sqrt(SolveAssignmentNetworkflow(cm))
}
for (i in 2:100){
mh <- muhat[1:10, 1:i]
nh <- nuhat[1:10, 1:i]
cm <- costMatrix(mh, nh, 2, 2)
w2_emp[i-1] <- sqrt(SolveAssignmentNetworkflow(cm))
}
w2_emp
for (i in 2:1000){
mh <- muhat[1:10, 1:i]
nh <- nuhat[1:10, 1:i]
cm <- costMatrix(mh, nh, 2, 2)
w2_emp[i-1] <- sqrt(SolveAssignmentNetworkflow(cm))
}
w2_emp
w2_emp_vars <- rep(0, 999)
w2_emp
w2_emp_vars
for (i in 2:1000){
w2_emp_vars <- var(w2_emp[1:i])
}
w2_emp_vars
for (i in 2:1000){
w2_emp_vars <- var(w2_emp[1:i])
}
w2_emp_vars
w2_emp_vars <- rep(0, 999)
for (i in 2:1000){
w2_emp_vars[i] <- var(w2_emp[1:i])
}
w2_emp_vars
var(w2_emp[1:i])
var(w2_emp[1:i])
i
var(w2_emp[1:1000])
w2_emp
w2_emp[1]
w2_emp[1000]
w2_emp[1001]
w2_emp_vars <- rep(0, 999)
for (i in 2:999){
w2_emp_vars[i] <- var(w2_emp[1:i])
}
w2_emp_vars
plot(2:1000, w2_emp_vars)
plot(2:1000, w2_emp_vars, log = "xy")
plot(log(2:1000), log(w2_emp_vars))
w2_emp_vars
w2_emp
var(w2_emp[900:1000])
var(w2_emp[900:1000])
w2_emp[900:1000]
w2_emp[900:999]
var(w2_emp[900:999])
var(w2_emp[1:999])
var(w2_emp[1:998])
var(w2_emp[1:999])
w2_emp <- c()
for (i in 500:1000){
mh <- muhat[1:10, 1:i]
nh <- nuhat[1:10, 1:i]
cm <- costMatrix(mh, nh, 2, 2)
w2_emp[i-1] <- sqrt(SolveAssignmentNetworkflow(cm))
}
w2_emp_vars <- rep(0, 999)
for (i in 2:999){
w2_emp_vars[i] <- var(w2_emp[1:i])
}
w2_emp_vars
plot(2:1000, w2_emp_vars, log = "xy")
w2_emp
for (i in 500:1000){
mh <- muhat[1:10, 500:i]
nh <- nuhat[1:10, 500:i]
cm <- costMatrix(mh, nh, 2, 2)
w2_emp[i-1] <- sqrt(SolveAssignmentNetworkflow(cm))
}
for (i in 501:1000){
mh <- muhat[1:10, 500:i]
nh <- nuhat[1:10, 500:i]
cm <- costMatrix(mh, nh, 2, 2)
w2_emp[i-1] <- sqrt(SolveAssignmentNetworkflow(cm))
}
w2_emp_vars <- rep(0, 499)
for (i in 2:499){
w2_emp_vars[i] <- var(w2_emp[1:i])
}
w2_emp_vars
w2_emp
w2_emp <- c()
for (i in 2:1000){
mh <- muhat[1:10, 1:i]
nh <- nuhat[1:10, 1:i]
cm <- costMatrix(mh, nh, 2, 2)
w2_emp[i-1] <- sqrt(SolveAssignmentNetworkflow(cm))
}
w2_emp_vars <- rep(0, 999)
for (i in 2:999){
w2_emp_vars[i] <- var(w2_emp[1:i])
}
w2_emp_vars
plot(2:1000, w2_emp_vars, log = "xy")
plot(log(2:1000), log(w2_emp_vars))
s
sadfasd
))
# Investigate:
# Easy ("Good"): Look at variance of Wp^p (wasserstein p distance to the p) and Wp when ?? = ?? as N increases
# Loop, store distance, compute estimator of sample variance (1/n ? sum((xi - x??)^2))
# var(c(10 9 8 7 6 5 4 3 2 1))
# pattern: want plot variance against N, definintely for Wp^p goes down faster than 1/n, interesting: find out the exponent.
# it's n^-c c> 1 but how big is this and how does it depend on dimension
# How to see what size of c is:
# Imagine I know a-priori it's log(var) = logc * c log(n)
# log log plot of variance against sample size then slope = c < -1
# Then take p^th root then calculate variance and then loglog plot of variance against sample size
# Pattern should be the same for whatever mertic and exponent p > 1
# Which exact metic to take and which exponent tot ake is pretty wide
# Start with euclidean norm exponent 2, then integer exponents
# Sample size up to 10,000
# Replicates: A couple
# Wasserstein takes a metric d and then (integral( d(x - y) ^p)^1/p
# d <- function(x, y, q = 2) {(sum(x - y)^q)^(1/q)} # = Lq-norm which then induces a metric but yeah
# preliminary investigation: CLT papers on Optimal transport ?? if I would like (only, otherwise do not, i repeat do not unless you would like)
# Came out february, good papers -> you must enjoy them. contains refernece to previous work which is pretty good
# https://arxiv.org/pdf/2102.06379.pdf
require(Rcpp)
sourceCpp("src/network_simplex_fast.cpp") # Compile and load the solver. The header files are also necessary.
sourceCpp("src/costMatrix.cpp")
n <- 1000 # Sample size
d <- 10   # Dimension
# 1.) Generate samples (they don't have to be normal)
muhat <- matrix(rnorm(n * d), nrow = d) # n samples from a standard normal, stored as one sample per column
nuhat <- matrix(rnorm(n * d), nrow = d)
# 2.) Compute the cost matrix
# If x_i is the i-th sample from mu, its entries are c_{ij} = 1/n * ||x_i - y_i||_2^2.
# In general, you'll do c_{ij} = 1/n * d(x_i, y_i)^p.
cost_mat <- costMatrix(muhat, nuhat, 2, 2) # L-2 metric, wasserstein 2 norm
# 3.) Compute the distance from the cost matrix
#w2_empirical <- sqrt(SolveAssignmentNetworkflow(cost_mat))
w2_emp <- c()
for (i in 2:n){
mh <- muhat[1:10, 1:i]
nh <- nuhat[1:10, 1:i]
cm <- costMatrix(mh, nh, 2, 2)
w2_emp[i-1] <- sqrt(SolveAssignmentNetworkflow(cm))
}
w2_emp_vars <- c()
for (i in 2:999){
w2_emp_vars[i] <- var(w2_emp[1:i])/i
}
w2_emp_vars
plot(2:1000, w2_emp_vars, log = "xy")
plot(log(2:1000), log(w2_emp_vars))
plot(2:1000, 1/(2:1000))
plot(2:1000, w2_emp_vars, log = "xy", type = l)
plot(2:1000, w2_emp_vars, log = "xy", type = "l")
plot(2:1000, 1/(2:1000), type = l, log = "xy")
plot(2:1000, 1/(2:1000), type = "l", log = "xy")
plot(log(2:1000), log(w2_emp_vars))
plot(2:1000, w2_emp_vars, log = "xy", type = "l")
plot(2:1000, 1/(2:1000), type = "l", log = "xy")
plot(2:1000, w2_emp_vars, log = "xy", type = "l")
library(tidyverse)
install.packages(("tidyverse"))
library(tidyverse)
w2_emp_vars
tibble(n = 2:999, `var/n` = w2_emp_vars)
tibble(n = 2:999, var = w2_emp_vars)
tibble(n = 2:1000, var = w2_emp_vars)
w2_emp[1:2]
var(w2_emp[1:2])
var(w2_emp[1:2])/2
w2_emp_vars
w2_emp_vars <- c()
for (i in 2:999){
w2_emp_vars[i-1] <- var(w2_emp[1:i])/i
}
tibble(n = 2:999, var = w2_emp_vars)
tibble(n = 2:999, var = w2_emp_vars, `1/n` = 1/2:999)
data = tibble(n = 2:999, var = w2_emp_vars, `1/n` = 1/2:999)
data
data <- tibble(n = 2:(n-1), var = w2_emp_vars, `1/n^p` = (1/2:m)^p)
library(tidyverse)
library(glue)
require(Rcpp)
sourceCpp("src/network_simplex_fast.cpp") # Compile and load the solver. The header files are also necessary.
sourceCpp("src/costMatrix.cpp")
n <- 100 # Sample size
d <- 10   # Dimension
p <- 2    # Wasserstein-p norm
# Investigate:
# Easy ("Good"): Look at variance of Wp^p (wasserstein p distance to the p) and Wp when ?? = ?? as N increases
# Loop, store distance, compute estimator of sample variance (1/n ? sum((xi - x??)^2))
# var(c(10 9 8 7 6 5 4 3 2 1))
# pattern: want plot variance against N, definintely for Wp^p goes down faster than 1/n, interesting: find out the exponent.
# it's n^-c c> 1 but how big is this and how does it depend on dimension
# How to see what size of c is:
# Imagine I know a-priori it's log(var) = logc * c log(n)
# log log plot of variance against sample size then slope = c < -1
# Then take p^th root then calculate variance and then loglog plot of variance against sample size
# Pattern should be the same for whatever mertic and exponent p > 1
# Which exact metic to take and which exponent tot ake is pretty wide
# Start with euclidean norm exponent 2, then integer exponents
# Sample size up to 10,000
# Replicates: A couple
# Wasserstein takes a metric d and then (integral( d(x - y) ^p)^1/p
# d <- function(x, y, q = 2) {(sum(x - y)^q)^(1/q)} # = Lq-norm which then induces a metric but yeah
# preliminary investigation: CLT papers on Optimal transport ?? if I would like (only, otherwise do not, i repeat do not unless you would like)
# Came out february, good papers -> you must enjoy them. contains refernece to previous work which is pretty good
# https://arxiv.org/pdf/2102.06379.pdf
library(tidyverse)
library(glue)
require(Rcpp)
sourceCpp("src/network_simplex_fast.cpp") # Compile and load the solver. The header files are also necessary.
sourceCpp("src/costMatrix.cpp")
n <- 100 # Sample size
d <- 10   # Dimension
p <- 2    # Wasserstein-p norm
# 1.) Generate samples (they don't have to be normal)
muhat <- matrix(rnorm(n * d), nrow = d) # n samples from a standard normal, stored as one sample per column
nuhat <- matrix(rnorm(n * d), nrow = d)
# 2.) Compute the cost matrix
# If x_i is the i-th sample from mu, its entries are c_{ij} = 1/n * ||x_i - y_i||_2^2.
# In general, you'll do c_{ij} = 1/n * d(x_i, y_i)^p.
cost_mat <- costMatrix(muhat, nuhat, 2, p) # d(x, y) = L-2 metric, Wasserstein 2 norm
sqrt(SolveAssignmentNetworkflow(1, cost_mat))
# 3.) Compute the distance from the cost matrix
#w2_empirical <- sqrt(SolveAssignmentNetworkflow(n, cost_mat))
w2_emp <- c()
for (i in 2:n){
w2_emp[i-1] <- (SolveAssignmentNetworkflow(i, cost_mat))^1/p
}
w2_emp_vars <- c()
for (i in 2:n-1){
w2_emp_vars[i-1] <- var(w2_emp[1:i])/(i^2)
}
w2_emp_vars
m = n-1
data <- tibble(n = 2:(n-1), var = w2_emp_vars, `1/n^p` = (1/2:m)^p)
data <- data %>%
pivot_longer(c("var", "1/n^p"), names_to = "variable")
data %>%
ggplot(aes(x = n, y = value, colour = variable)) +
geom_line() +
scale_y_log10() +
scale_x_log10() +
scale_colour_discrete(name = "", labels = c(glue("1/n^{p}"), "Empirical Variance")) +
labs(x = "Number of datapoints",
y = "Variance",
colour = "") +
theme_bw()
data
# Investigate:
# Easy ("Good"): Look at variance of Wp^p (wasserstein p distance to the p) and Wp when ?? = ?? as N increases
# Loop, store distance, compute estimator of sample variance (1/n ? sum((xi - x??)^2))
# var(c(10 9 8 7 6 5 4 3 2 1))
# pattern: want plot variance against N, definintely for Wp^p goes down faster than 1/n, interesting: find out the exponent.
# it's n^-c c> 1 but how big is this and how does it depend on dimension
# How to see what size of c is:
# Imagine I know a-priori it's log(var) = logc * c log(n)
# log log plot of variance against sample size then slope = c < -1
# Then take p^th root then calculate variance and then loglog plot of variance against sample size
# Pattern should be the same for whatever mertic and exponent p > 1
# Which exact metic to take and which exponent tot ake is pretty wide
# Start with euclidean norm exponent 2, then integer exponents
# Sample size up to 10,000
# Replicates: A couple
# Wasserstein takes a metric d and then (integral( d(x - y) ^p)^1/p
# d <- function(x, y, q = 2) {(sum(x - y)^q)^(1/q)} # = Lq-norm which then induces a metric but yeah
# preliminary investigation: CLT papers on Optimal transport ?? if I would like (only, otherwise do not, i repeat do not unless you would like)
# Came out february, good papers -> you must enjoy them. contains refernece to previous work which is pretty good
# https://arxiv.org/pdf/2102.06379.pdf
library(tidyverse)
library(glue)
require(Rcpp)
sourceCpp("src/network_simplex_fast.cpp") # Compile and load the solver. The header files are also necessary.
sourceCpp("src/costMatrix.cpp")
n <- 1000 # Sample size
d <- 10   # Dimension
p <- 2    # Wasserstein-p norm
# 1.) Generate samples (they don't have to be normal)
muhat <- matrix(rnorm(n * d), nrow = d) # n samples from a standard normal, stored as one sample per column
nuhat <- matrix(rnorm(n * d), nrow = d)
# 2.) Compute the cost matrix
# If x_i is the i-th sample from mu, its entries are c_{ij} = 1/n * ||x_i - y_i||_2^2.
# In general, you'll do c_{ij} = 1/n * d(x_i, y_i)^p.
cost_mat <- costMatrix(muhat, nuhat, 2, p) # d(x, y) = L-2 metric, Wasserstein 2 norm
sqrt(SolveAssignmentNetworkflow(1, cost_mat))
# 3.) Compute the distance from the cost matrix
#w2_empirical <- sqrt(SolveAssignmentNetworkflow(n, cost_mat))
w2_emp <- c()
for (i in 2:n){
w2_emp[i-1] <- (SolveAssignmentNetworkflow(i, cost_mat))^1/p
}
w2_emp_vars <- c()
for (i in 2:n-1){
w2_emp_vars[i-1] <- var(w2_emp[1:i])/(i^2)
}
w2_emp_vars
m = n-1
data <- tibble(n = 2:(n-1), var = w2_emp_vars, `1/n^p` = (1/2:m)^p)
data <- data %>%
pivot_longer(c("var", "1/n^p"), names_to = "variable")
data %>%
ggplot(aes(x = n, y = value, colour = variable)) +
geom_line() +
scale_y_log10() +
scale_x_log10() +
scale_colour_discrete(name = "", labels = c(glue("1/n^{p}"), "Empirical Variance")) +
labs(x = "Number of datapoints",
y = "Variance",
colour = "") +
theme_bw()
data
data %>%
ggplot(aes(x = n, y = value, colour = variable)) +
geom_line(size = 1.2) +
scale_y_log10() +
scale_x_log10() +
scale_colour_discrete(name = "", labels = c(glue("1/n^{p}"), "Empirical Variance")) +
labs(x = "Number of datapoints",
y = "Variance",
colour = "") +
theme_bw()
data %>%
ggplot(aes(x = n, y = value, colour = variable)) +
geom_line(size = 1) +
scale_y_log10() +
scale_x_log10() +
scale_colour_discrete(name = "", labels = c(glue("1/n^{p}"), "Empirical Variance")) +
labs(x = "Number of datapoints",
y = "Variance",
colour = "") +
theme_bw()
data <- tibble(n = 2:(n-1), var = w2_emp_vars, `1/n^p` = (1/2:m)^p)
data_plot <- data %>%
pivot_longer(c("var", "1/n^p"), names_to = "variable")
data_plot %>%
ggplot(aes(x = n, y = value, colour = variable)) +
geom_line(size = 1) +
scale_y_log10() +
scale_x_log10() +
scale_colour_discrete(name = "", labels = c(glue("1/n^{p}"), "Empirical Variance")) +
labs(x = "Number of datapoints",
y = "Variance",
colour = "") +
theme_bw()
